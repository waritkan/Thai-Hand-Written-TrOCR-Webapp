{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 1: Install & Import\n",
    "# ============================================================\n",
    "# !pip install torch transformers datasets sentencepiece pillow tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    AutoImageProcessor,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import sentencepiece as spm\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe15b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2: Define Thai Tokenizer Class\n",
    "# ============================================================\n",
    "class ThaiTokenizerFixed(PreTrainedTokenizer):\n",
    "    \"\"\"Fixed Thai SentencePiece Tokenizer with proper special token handling\"\"\"\n",
    "    \n",
    "    vocab_files_names = {\"vocab_file\": \"spm.model\"}\n",
    "    \n",
    "    def __init__(self, vocab_file=None, **kwargs):\n",
    "        self.vocab_file = vocab_file or 'thai_sp_30000.model'\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(self.vocab_file)\n",
    "        \n",
    "        super().__init__(\n",
    "            pad_token=\"<pad>\",\n",
    "            unk_token=\"<unk>\",\n",
    "            bos_token=\"<s>\",\n",
    "            eos_token=\"</s>\",\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def pad_token_id(self):\n",
    "        return 0\n",
    "    \n",
    "    @property\n",
    "    def unk_token_id(self):\n",
    "        return 1\n",
    "    \n",
    "    @property\n",
    "    def bos_token_id(self):\n",
    "        return 2\n",
    "    \n",
    "    @property\n",
    "    def eos_token_id(self):\n",
    "        return 3\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self.sp.vocab_size()\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return {self.sp.id_to_piece(i): i for i in range(self.sp.vocab_size())}\n",
    "    \n",
    "    def _tokenize(self, text):\n",
    "        return self.sp.encode_as_pieces(text)\n",
    "    \n",
    "    def _convert_token_to_id(self, token):\n",
    "        return self.sp.piece_to_id(token)\n",
    "    \n",
    "    def _convert_id_to_token(self, index):\n",
    "        return self.sp.id_to_piece(index)\n",
    "    \n",
    "    def convert_tokens_to_string(self, tokens):\n",
    "        return self.sp.decode_pieces(tokens)\n",
    "    \n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        \"\"\"Add BOS and EOS tokens\"\"\"\n",
    "        bos = [self.bos_token_id]\n",
    "        eos = [self.eos_token_id]\n",
    "        \n",
    "        if token_ids_1 is None:\n",
    "            return bos + token_ids_0 + eos\n",
    "        return bos + token_ids_0 + eos + bos + token_ids_1 + eos\n",
    "    \n",
    "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
    "        if already_has_special_tokens:\n",
    "            return super().get_special_tokens_mask(\n",
    "                token_ids_0=token_ids_0, \n",
    "                token_ids_1=token_ids_1, \n",
    "                already_has_special_tokens=True\n",
    "            )\n",
    "        \n",
    "        if token_ids_1 is None:\n",
    "            return [1] + ([0] * len(token_ids_0)) + [1]\n",
    "        return [1] + ([0] * len(token_ids_0)) + [1] + [1] + ([0] * len(token_ids_1)) + [1]\n",
    "    \n",
    "    def save_vocabulary(self, save_directory, filename_prefix=None):\n",
    "        if not os.path.isdir(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "        \n",
    "        out_file = os.path.join(\n",
    "            save_directory,\n",
    "            (filename_prefix + \"-\" if filename_prefix else \"\") + \"spm.model\"\n",
    "        )\n",
    "        \n",
    "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_file):\n",
    "            shutil.copy(self.vocab_file, out_file)\n",
    "        \n",
    "        return (out_file,)\n",
    "\n",
    "print(\"‚úÖ ThaiTokenizerFixed class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51eb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: Define Dataset Class\n",
    "# ============================================================\n",
    "class ThaiHandwritingDatasetFixed(Dataset):\n",
    "    \"\"\"Dataset with proper BOS/EOS tokens\"\"\"\n",
    "    def __init__(self, dataset, tokenizer, image_processor, max_length=128):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_processor = image_processor\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        # Process image\n",
    "        image = item['image']\n",
    "        if isinstance(image, dict):\n",
    "            image = Image.open(io.BytesIO(image['bytes']))\n",
    "        elif not isinstance(image, Image.Image):\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        pixel_values = self.image_processor(image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "        \n",
    "        # Process text with special tokens\n",
    "        text = item['text']\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        input_ids = encoding['input_ids'].squeeze(0)\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': labels,\n",
    "            'text': text,\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function\"\"\"\n",
    "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    texts = [item['text'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'pixel_values': pixel_values,\n",
    "        'labels': labels,\n",
    "        'texts': texts,\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Dataset class and collate_fn defined\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8b6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 4: Define Trainer Class (with Resume Support)\n",
    "# ============================================================\n",
    "class Trainer:\n",
    "    \"\"\"Trainer for TrOCR with Thai tokenizer - supports proper resume\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        tokenizer,\n",
    "        device='cuda',\n",
    "        learning_rate=5e-5,\n",
    "        num_epochs=10,\n",
    "        warmup_steps=500,\n",
    "        output_dir='./checkpoints',\n",
    "        gradient_accumulation_steps=1,\n",
    "        resume_from=None,  # ‚≠ê Path to checkpoint for resume\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.num_epochs = num_epochs\n",
    "        self.output_dir = output_dir\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Calculate total steps\n",
    "        self.steps_per_epoch = len(train_dataloader) // gradient_accumulation_steps\n",
    "        total_steps = self.steps_per_epoch * num_epochs\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # Initialize scheduler\n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        # Training state\n",
    "        self.start_epoch = 0\n",
    "        self.global_step = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.training_history = []\n",
    "        \n",
    "        # ‚≠ê Resume from checkpoint if provided\n",
    "        if resume_from is not None:\n",
    "            self._load_checkpoint(resume_from)\n",
    "    \n",
    "    def _load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load checkpoint and restore training state\"\"\"\n",
    "        print(f\"\\nüìÇ Loading checkpoint from: {checkpoint_path}\")\n",
    "        \n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        # Restore model\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(\"   ‚úÖ Model restored\")\n",
    "        \n",
    "        # Restore optimizer\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(\"   ‚úÖ Optimizer restored\")\n",
    "        \n",
    "        # Restore scheduler\n",
    "        if 'scheduler_state_dict' in checkpoint:\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            print(\"   ‚úÖ Scheduler restored\")\n",
    "        \n",
    "        # Restore training state\n",
    "        self.start_epoch = checkpoint.get('epoch', 0) + 1  # Start from next epoch\n",
    "        self.global_step = checkpoint.get('global_step', 0)\n",
    "        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        \n",
    "        if 'training_history' in checkpoint:\n",
    "            self.training_history = checkpoint['training_history']\n",
    "        \n",
    "        # Verify LR\n",
    "        actual_lr = self.optimizer.param_groups[0]['lr']\n",
    "        print(f\"\\nüìä Resume State:\")\n",
    "        print(f\"   Completed epochs: {self.start_epoch}\")\n",
    "        print(f\"   Global step: {self.global_step}\")\n",
    "        print(f\"   Best val loss: {self.best_val_loss:.4f}\")\n",
    "        print(f\"   Current LR: {actual_lr:.2e}\")\n",
    "    \n",
    "    def _set_learning_rate(self, new_lr):\n",
    "        \"\"\"Manually set learning rate (use with caution)\"\"\"\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = new_lr\n",
    "        print(f\"‚ö†Ô∏è  LR manually set to: {new_lr:.2e}\")\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        epoch_steps = 0\n",
    "        \n",
    "        progress_bar = tqdm(\n",
    "            self.train_dataloader, \n",
    "            desc=f\"Epoch {epoch+1}/{self.start_epoch + self.num_epochs}\"\n",
    "        )\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            pixel_values = batch['pixel_values'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            outputs = self.model(\n",
    "                pixel_values=pixel_values,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss / self.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                self.global_step += 1\n",
    "                epoch_steps += 1\n",
    "            \n",
    "            total_loss += loss.item() * self.gradient_accumulation_steps\n",
    "            \n",
    "            # Show current LR in progress bar\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item() * self.gradient_accumulation_steps:.4f}\",\n",
    "                'lr': f\"{current_lr:.2e}\"\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_dataloader, desc=\"Validating\"):\n",
    "                pixel_values = batch['pixel_values'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    pixel_values=pixel_values,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                total_loss += outputs.loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(self.val_dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        \"\"\"Save checkpoint with full training state\"\"\"\n",
    "        # Record history\n",
    "        self.training_history.append({\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'lr': self.optimizer.param_groups[0]['lr'],\n",
    "            'global_step': self.global_step,\n",
    "        })\n",
    "        \n",
    "        # Save latest checkpoint\n",
    "        latest_path = os.path.join(self.output_dir, 'checkpoint-latest.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'global_step': self.global_step,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'best_val_loss': self.best_val_loss,\n",
    "            'training_history': self.training_history,\n",
    "            'config': {\n",
    "                'learning_rate': self.learning_rate,\n",
    "                'gradient_accumulation_steps': self.gradient_accumulation_steps,\n",
    "            }\n",
    "        }, latest_path)\n",
    "        print(f\"üíæ Checkpoint saved (epoch {epoch+1}, step {self.global_step})\")\n",
    "        \n",
    "        # Save periodic checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            periodic_path = os.path.join(self.output_dir, f'checkpoint-epoch-{epoch+1}.pt')\n",
    "            shutil.copy(latest_path, periodic_path)\n",
    "            print(f\"üìÅ Periodic checkpoint: {periodic_path}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            best_path = os.path.join(self.output_dir, 'best_model.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'global_step': self.global_step,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, best_path)\n",
    "            print(f\"üèÜ New best model! Val Loss: {val_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"üìä Val loss: {val_loss:.4f} (best: {self.best_val_loss:.4f})\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Full training loop with resume support\"\"\"\n",
    "        end_epoch = self.start_epoch + self.num_epochs\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üöÄ TRAINING START\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"   From epoch: {self.start_epoch + 1}\")\n",
    "        print(f\"   To epoch: {end_epoch}\")\n",
    "        print(f\"   Total new epochs: {self.num_epochs}\")\n",
    "        print(f\"   Learning rate: {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        print(f\"   Batch size: {self.train_dataloader.batch_size}\")\n",
    "        print(f\"   Gradient accumulation: {self.gradient_accumulation_steps}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        for epoch in range(self.start_epoch, end_epoch):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"üìä Epoch {epoch+1}/{end_epoch}\")\n",
    "            print(f\"   Global step: {self.global_step}\")\n",
    "            print(f\"   LR: {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            print(f\"üìà Train Loss: {train_loss:.5f}\")\n",
    "            \n",
    "            val_loss = self.validate()\n",
    "            print(f\"üìâ Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            self.save_checkpoint(epoch, val_loss)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ TRAINING COMPLETED\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"   Total epochs trained: {end_epoch}\")\n",
    "        print(f\"   Final global step: {self.global_step}\")\n",
    "        print(f\"   Best validation loss: {self.best_val_loss:.4f}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "print(\"‚úÖ Trainer class defined (with resume support)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5: Setup & Train\n",
    "# ============================================================\n",
    "def setup_training(\n",
    "    # Paths\n",
    "    spm_model_path='thai_sp_30000.model',\n",
    "    output_dir='./thai-trocr-custom-tokenizer',\n",
    "    checkpoint_path=None,  # None = train from scratch, path = resume\n",
    "    \n",
    "    # Training params\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_epochs=100,\n",
    "    warmup_steps=500,\n",
    "    gradient_accumulation_steps=2,\n",
    "    max_length=128,\n",
    "    \n",
    "    # Data\n",
    "    dataset_name=\"Pongthorn/HW-Sentence\",\n",
    "    train_split=\"train\",\n",
    "    val_split=\"test\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Setup and run training\n",
    "    \n",
    "    Usage:\n",
    "        # Train from scratch\n",
    "        setup_training(num_epochs=100)\n",
    "        \n",
    "        # Resume training\n",
    "        setup_training(\n",
    "            checkpoint_path='./thai-trocr-custom-tokenizer/checkpoint-latest.pt',\n",
    "            num_epochs=50,  # Additional epochs to train\n",
    "            learning_rate=5e-6,  # Can adjust LR for fine-tuning\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"üñ•Ô∏è  Device: {DEVICE}\")\n",
    "    \n",
    "    # ========== Load Tokenizer ==========\n",
    "    print(\"\\nüìù Loading tokenizer...\")\n",
    "    tokenizer = ThaiTokenizerFixed(vocab_file=spm_model_path)\n",
    "    print(f\"   Vocab size: {tokenizer.vocab_size}\")\n",
    "    \n",
    "    # ========== Load Image Processor ==========\n",
    "    print(\"\\nüñºÔ∏è  Loading image processor...\")\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\n",
    "        \"microsoft/trocr-base-handwritten\"\n",
    "    )\n",
    "    \n",
    "    # ========== Load Dataset ==========\n",
    "    print(f\"\\nüìö Loading dataset: {dataset_name}\")\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(f\"   Train samples: {len(dataset[train_split])}\")\n",
    "    print(f\"   Val samples: {len(dataset[val_split])}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ThaiHandwritingDatasetFixed(\n",
    "        dataset[train_split], tokenizer, image_processor, max_length\n",
    "    )\n",
    "    val_dataset = ThaiHandwritingDatasetFixed(\n",
    "        dataset[val_split], tokenizer, image_processor, max_length\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"   Train batches: {len(train_dataloader)}\")\n",
    "    print(f\"   Val batches: {len(val_dataloader)}\")\n",
    "    \n",
    "    # ========== Load Model ==========\n",
    "    print(\"\\nü§ñ Loading model...\")\n",
    "    \n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        # Resume: Load base model first, checkpoint will restore weights\n",
    "        print(\"   Mode: RESUME TRAINING\")\n",
    "        model = VisionEncoderDecoderModel.from_pretrained(\n",
    "            \"microsoft/trocr-base-handwritten\"\n",
    "        )\n",
    "    else:\n",
    "        # Fresh start\n",
    "        print(\"   Mode: TRAIN FROM SCRATCH\")\n",
    "        model = VisionEncoderDecoderModel.from_pretrained(\n",
    "            \"microsoft/trocr-base-handwritten\"\n",
    "        )\n",
    "    \n",
    "    # Resize embeddings for Thai tokenizer\n",
    "    model.decoder.resize_token_embeddings(tokenizer.vocab_size)\n",
    "    \n",
    "    # Configure model\n",
    "    model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.eos_token_id = tokenizer.eos_token_id\n",
    "    model.config.vocab_size = tokenizer.vocab_size\n",
    "    model.config.max_length = max_length\n",
    "    model.config.early_stopping = True\n",
    "    model.config.num_beams = 4\n",
    "    \n",
    "    print(f\"   Decoder vocab size: {model.config.vocab_size}\")\n",
    "    \n",
    "    # ========== Create Trainer ==========\n",
    "    print(\"\\nüéØ Initializing trainer...\")\n",
    "    \n",
    "    # Determine warmup steps\n",
    "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        # Resume: No warmup needed (scheduler state will be restored)\n",
    "        actual_warmup = warmup_steps  # Will be overridden by scheduler state\n",
    "    else:\n",
    "        actual_warmup = warmup_steps\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        tokenizer=tokenizer,\n",
    "        device=DEVICE,\n",
    "        learning_rate=learning_rate,\n",
    "        num_epochs=num_epochs,\n",
    "        warmup_steps=actual_warmup,\n",
    "        output_dir=output_dir,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        resume_from=checkpoint_path,  # ‚≠ê This handles everything!\n",
    "    )\n",
    "    \n",
    "    # ========== Start Training ==========\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HOW TO USE\n",
    "# ============================================================\n",
    "\"\"\"\n",
    "# ===== TRAIN FROM SCRATCH =====\n",
    "trainer = setup_training(\n",
    "    spm_model_path='thai_sp_30000.model',\n",
    "    output_dir='./thai-trocr-custom-tokenizer',\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_epochs=100,\n",
    "    warmup_steps=500,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "\n",
    "# ===== RESUME TRAINING (Continue with same settings) =====\n",
    "trainer = setup_training(\n",
    "    spm_model_path='thai_sp_30000.model',\n",
    "    output_dir='./thai-trocr-custom-tokenizer',\n",
    "    checkpoint_path='./thai-trocr-custom-tokenizer/checkpoint-latest.pt',\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-5,  # Will be restored from checkpoint\n",
    "    num_epochs=50,       # Additional epochs to train\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "\n",
    "# ===== RESUME WITH NEW LEARNING RATE (Fine-tuning) =====\n",
    "# If you want to change LR after resuming, manually set it:\n",
    "trainer = setup_training(\n",
    "    checkpoint_path='./thai-trocr-custom-tokenizer/checkpoint-latest.pt',\n",
    "    num_epochs=50,\n",
    ")\n",
    "# Then manually adjust LR if needed:\n",
    "# trainer._set_learning_rate(1e-6)\n",
    "# trainer.train()  # Won't work directly, need to modify\n",
    "\n",
    "\n",
    "# ===== QUICK RESUME (just run this) =====\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    checkpoint = './thai-trocr-custom-tokenizer/checkpoint-latest.pt'\n",
    "    \n",
    "    if os.path.exists(checkpoint):\n",
    "        print(\"üìÇ Found checkpoint, resuming...\")\n",
    "        trainer = setup_training(\n",
    "            checkpoint_path=checkpoint,\n",
    "            num_epochs=50,\n",
    "        )\n",
    "    else:\n",
    "        print(\"üÜï No checkpoint found, starting fresh...\")\n",
    "        trainer = setup_training(\n",
    "            num_epochs=100,\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL CELLS READY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTo start training, run:\")\n",
    "print(\"  trainer = setup_training(num_epochs=100)\")\n",
    "print(\"\\nTo resume training, run:\")\n",
    "print(\"  trainer = setup_training(\")\n",
    "print(\"      checkpoint_path='./thai-trocr-custom-tokenizer/checkpoint-latest.pt',\")\n",
    "print(\"      num_epochs=50,\")\n",
    "print(\"  )\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dff06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6: Test Model\n",
    "# ============================================================\n",
    "import random\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üß™ TESTING MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ‚≠ê ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ trainer ‡∏à‡∏≤‡∏Å Cell 5 ‡∏Å‡πà‡∏≠‡∏ô\n",
    "# ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà:\n",
    "# trainer = setup_training(\n",
    "#     checkpoint_path='./thai-trocr-custom-tokenizer/checkpoint-latest.pt',\n",
    "#     num_epochs=0,  # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á train ‡πÄ‡∏û‡∏¥‡πà‡∏°\n",
    "# )\n",
    "\n",
    "# ‚≠ê ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å checkpoint\n",
    "USE_CHECKPOINT = \"latest\"  # \"latest\", \"best\", or \"current\"\n",
    "\n",
    "model = trainer.model\n",
    "tokenizer = trainer.tokenizer\n",
    "DEVICE = trainer.device\n",
    "\n",
    "if USE_CHECKPOINT == \"latest\":\n",
    "    print(\"\\nüì• Loading checkpoint-latest.pt...\")\n",
    "    ckpt = torch.load('./thai-trocr-custom-tokenizer/checkpoint-latest.pt', map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    print(f\"‚úÖ Loaded: Epoch {ckpt['epoch']+1}, Loss {ckpt['val_loss']:.4f}\")\n",
    "\n",
    "elif USE_CHECKPOINT == \"best\":\n",
    "    print(\"\\nüì• Loading best_model.pt...\")\n",
    "    ckpt = torch.load('./thai-trocr-custom-tokenizer/best_model.pt', map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    print(f\"‚úÖ Loaded: Epoch {ckpt['epoch']+1}, Loss {ckpt['val_loss']:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚úÖ Using current model in trainer\")\n",
    "    ckpt = None\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Test function\n",
    "def test_model_samples(model, dataloader, tokenizer, device, num_samples=10, title=\"Test\"):\n",
    "    \"\"\"Test model with random samples\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Collect all samples\n",
    "    all_samples = []\n",
    "    for batch in dataloader:\n",
    "        for i in range(batch['pixel_values'].size(0)):\n",
    "            all_samples.append({\n",
    "                'pixel_values': batch['pixel_values'][i],\n",
    "                'text': batch['texts'][i]\n",
    "            })\n",
    "        if len(all_samples) >= 100:  # Enough for random sampling\n",
    "            break\n",
    "    \n",
    "    # Random sample\n",
    "    samples = random.sample(all_samples, min(num_samples, len(all_samples)))\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä {title}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, sample in enumerate(samples):\n",
    "            ground_truth = sample['text']\n",
    "            pixel_values = sample['pixel_values'].unsqueeze(0).to(device)\n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "                pixel_values,\n",
    "                max_length=150,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                repetition_penalty=1.5,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                bos_token_id=tokenizer.bos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            \n",
    "            predicted = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Character accuracy\n",
    "            correct = sum(1 for a, b in zip(predicted, ground_truth) if a == b)\n",
    "            accuracy = correct / max(len(ground_truth), 1) * 100\n",
    "            \n",
    "            results.append({\n",
    "                'ground_truth': ground_truth,\n",
    "                'predicted': predicted,\n",
    "                'accuracy': accuracy\n",
    "            })\n",
    "            \n",
    "            print(f\"Sample {idx+1}/{num_samples}\")\n",
    "            print(f\"‚îú‚îÄ GT:   {ground_truth}\")\n",
    "            print(f\"‚îú‚îÄ Pred: {predicted}\")\n",
    "            print(f\"‚îú‚îÄ Acc:  {accuracy:.1f}%\")\n",
    "            print(f\"‚îî‚îÄ {'‚úÖ MATCH' if ground_truth == predicted else '‚ùå'}\")\n",
    "            print()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run tests\n",
    "train_results = test_model_samples(\n",
    "    model, trainer.train_dataloader, tokenizer, DEVICE, \n",
    "    num_samples=10, title=\"üéØ TRAIN SET\"\n",
    ")\n",
    "\n",
    "val_results = test_model_samples(\n",
    "    model, trainer.val_dataloader, tokenizer, DEVICE,\n",
    "    num_samples=10, title=\"üéØ VALIDATION SET\"\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üìà SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "train_perfect = sum(1 for r in train_results if r['ground_truth'] == r['predicted'])\n",
    "val_perfect = sum(1 for r in val_results if r['ground_truth'] == r['predicted'])\n",
    "train_acc = sum(r['accuracy'] for r in train_results) / len(train_results)\n",
    "val_acc = sum(r['accuracy'] for r in val_results) / len(val_results)\n",
    "\n",
    "print(f\"\\nüéØ Train: {train_perfect}/10 perfect, {train_acc:.1f}% avg char acc\")\n",
    "print(f\"üéØ Val:   {val_perfect}/10 perfect, {val_acc:.1f}% avg char acc\")\n",
    "print(\"\\n‚úÖ Testing completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
