{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Test Model Accuracy\n",
    "‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• OCR ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from PIL import Image\n",
    "import sentencepiece as spm\n",
    "from transformers import VisionEncoderDecoderModel, TrOCRProcessor, ViTImageProcessor\n",
    "from IPython.display import display, HTML\n",
    "import glob\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = r'e:\\TrOCR_Antigravity'\n",
    "MODEL_PATH = os.path.join(BASE_DIR, 'Model', 'best_model.pt')\n",
    "TOKENIZER_PATH = os.path.join(BASE_DIR, 'Model_Implement', 'thai_sp_30000.model')\n",
    "\n",
    "print(f'Model path: {MODEL_PATH}')\n",
    "print(f'Tokenizer path: {TOKENIZER_PATH}')\n",
    "print(f'Model exists: {os.path.exists(MODEL_PATH)}')\n",
    "print(f'Tokenizer exists: {os.path.exists(TOKENIZER_PATH)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thai Tokenizer Class\n",
    "class ThaiTokenizer:\n",
    "    def __init__(self, model_path):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(model_path)\n",
    "        self.vocab_size = self.sp.GetPieceSize()\n",
    "        \n",
    "        # Special tokens\n",
    "        self.bos_token_id = self.sp.PieceToId('<s>')\n",
    "        self.eos_token_id = self.sp.PieceToId('</s>')\n",
    "        self.pad_token_id = self.sp.PieceToId('<pad>') if self.sp.PieceToId('<pad>') != -1 else 0\n",
    "        self.unk_token_id = self.sp.PieceToId('<unk>')\n",
    "        \n",
    "        print(f'Vocab size: {self.vocab_size}')\n",
    "        print(f'BOS: {self.bos_token_id}, EOS: {self.eos_token_id}, PAD: {self.pad_token_id}')\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return self.sp.EncodeAsIds(text)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        if isinstance(ids, torch.Tensor):\n",
    "            ids = ids.tolist()\n",
    "        # Filter special tokens\n",
    "        ids = [i for i in ids if i not in [self.bos_token_id, self.eos_token_id, self.pad_token_id]]\n",
    "        return self.sp.DecodeIds(ids)\n",
    "    \n",
    "    def batch_decode(self, batch_ids, skip_special_tokens=True):\n",
    "        return [self.decode(ids) for ids in batch_ids]\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = ThaiTokenizer(TOKENIZER_PATH)\n",
    "print('Tokenizer loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "print('Loading model...')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Load state dict\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "\n",
    "# Create model\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "\n",
    "# Resize token embeddings\n",
    "model.decoder.resize_token_embeddings(tokenizer.vocab_size)\n",
    "\n",
    "# Load weights\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "else:\n",
    "    model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load image processor\n",
    "image_processor = ViTImageProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict(image_path):\n",
    "    \"\"\"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\"\"\"\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    pixel_values = image_processor(image, return_tensors='pt').pixel_values.to(device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            pixel_values,\n",
    "            max_length=128,\n",
    "            num_beams=4,\n",
    "            decoder_start_token_id=tokenizer.bos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # Decode\n",
    "    text = tokenizer.decode(generated_ids[0])\n",
    "    return text\n",
    "\n",
    "print('Prediction function ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with existing sample images\n",
    "sample_dir = os.path.join(BASE_DIR, 'webapp', 'static', 'sample_images')\n",
    "print(f'Sample directory: {sample_dir}')\n",
    "print(f'Exists: {os.path.exists(sample_dir)}')\n",
    "\n",
    "if os.path.exists(sample_dir):\n",
    "    for img_file in os.listdir(sample_dir):\n",
    "        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(sample_dir, img_file)\n",
    "            print(f'\\n--- {img_file} ---')\n",
    "            \n",
    "            # Show image\n",
    "            img = Image.open(img_path)\n",
    "            display(img)\n",
    "            \n",
    "            # Predict\n",
    "            result = predict(img_path)\n",
    "            print(f'Prediction: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å folder ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î\n",
    "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `TEST_FOLDER` ‡πÄ‡∏õ‡πá‡∏ô path ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î folder ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "# ========================================\n",
    "TEST_FOLDER = r'e:\\TrOCR_Antigravity\\test_images'  # <-- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á folder ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ\n",
    "if not os.path.exists(TEST_FOLDER):\n",
    "    os.makedirs(TEST_FOLDER)\n",
    "    print(f'Created folder: {TEST_FOLDER}')\n",
    "    print('‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô folder ‡∏ô‡∏µ‡πâ')\n",
    "else:\n",
    "    print(f'Test folder: {TEST_FOLDER}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô folder\n",
    "results = []\n",
    "\n",
    "image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.webp')\n",
    "image_files = [f for f in os.listdir(TEST_FOLDER) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "print(f'Found {len(image_files)} images\\n')\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(TEST_FOLDER, img_file)\n",
    "    \n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'File: {img_file}')\n",
    "    print(f'{\"=\"*50}')\n",
    "    \n",
    "    # Show image\n",
    "    img = Image.open(img_path)\n",
    "    # Resize for display if too large\n",
    "    max_width = 600\n",
    "    if img.width > max_width:\n",
    "        ratio = max_width / img.width\n",
    "        img_display = img.resize((max_width, int(img.height * ratio)))\n",
    "    else:\n",
    "        img_display = img\n",
    "    display(img_display)\n",
    "    \n",
    "    # Predict\n",
    "    try:\n",
    "        result = predict(img_path)\n",
    "        print(f'\\nüî§ Prediction: {result}')\n",
    "        results.append({'file': img_file, 'prediction': result, 'path': img_path})\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        results.append({'file': img_file, 'prediction': f'ERROR: {e}', 'path': img_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "print('\\n' + '='*60)\n",
    "print('‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î')\n",
    "print('='*60)\n",
    "\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {r['file']}\")\n",
    "    print(f\"   ‚Üí {r['prediction']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß\n",
    "‡πÉ‡∏™‡πà path ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß\n",
    "# ========================================\n",
    "SINGLE_IMAGE = r''  # <-- ‡πÉ‡∏™‡πà path ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà\n",
    "\n",
    "if SINGLE_IMAGE and os.path.exists(SINGLE_IMAGE):\n",
    "    print(f'Testing: {SINGLE_IMAGE}')\n",
    "    \n",
    "    # Show image\n",
    "    img = Image.open(SINGLE_IMAGE)\n",
    "    display(img)\n",
    "    \n",
    "    # Predict\n",
    "    result = predict(SINGLE_IMAGE)\n",
    "    print(f'\\nüî§ Prediction: {result}')\n",
    "else:\n",
    "    print('‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà path ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô SINGLE_IMAGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô Sample\n",
    "‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ copy ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÑ‡∏õ‡∏ó‡∏µ‡πà `webapp/static/sample_images/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# ========================================\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô sample\n",
    "# ========================================\n",
    "SELECTED_IMAGES = [\n",
    "    # ‡πÉ‡∏™‡πà path ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô:\n",
    "    # r'e:\\TrOCR_Antigravity\\test_images\\good_image1.jpg',\n",
    "    # r'e:\\TrOCR_Antigravity\\test_images\\good_image2.jpg',\n",
    "]\n",
    "\n",
    "SAMPLE_DIR = os.path.join(BASE_DIR, 'webapp', 'static', 'sample_images')\n",
    "\n",
    "for i, img_path in enumerate(SELECTED_IMAGES, 4):  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å sample4\n",
    "    if os.path.exists(img_path):\n",
    "        ext = os.path.splitext(img_path)[1]\n",
    "        dest = os.path.join(SAMPLE_DIR, f'sample{i}{ext}')\n",
    "        shutil.copy2(img_path, dest)\n",
    "        print(f'Copied: {img_path} -> {dest}')\n",
    "    else:\n",
    "        print(f'Not found: {img_path}')\n",
    "\n",
    "print('\\nDone! ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö sample_images folder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
